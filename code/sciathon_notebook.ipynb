{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WAvmZJ5uG6E_"
   },
   "source": [
    "The goal is to extract info about twitter users.\n",
    "1. extract their past tweets\n",
    "2. extract thier network (followers and following)\n",
    "3. extract a random sample of the tweets of the follwers\n",
    "4. check if the tweets include text about climate change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJQjEqbc91j3"
   },
   "source": [
    "#Technical considerations\n",
    "\n",
    "To compute the measures within the scope of this Sciathon, and due to twitter API limitations, we restricted our analysis to 8 accounts. These accounts represent users that are climate change activists, deniers, related to the lindau nobel meetings or should be agnostic to the subject. The percentage of tweets on climate change was measured on a subset of 200 tweets per account where retweets were counted the same as regular tweets. Followers with less than 10 tweets in total were excluded from the analysis. For the network analysis, we extracted the first 10,000 listed followers of each account and compared them to the first 10,000 followers of Greta Thunberg, who has many followers and actively tweets about climate change.\n",
    "The analyses were done using twitter developer API wrapped in the Python package tweepy and the R package rtweet to calculate the account metrics. Plots and analyses were performed in Python with numpy, pandas and matplotlib and R. \n",
    "\n",
    "**NOTE:** As real-time data was used, the analysis cannot be replicated with identical results. Though the general trends are expected to be consistent over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "Ka_yb_S5GXkb",
    "outputId": "95c21117-927b-45e1-a081-70d262f702b8"
   },
   "outputs": [],
   "source": [
    "# alternative to conda\n",
    "# !pip install tweepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4iZcSILsO4As"
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll ~/twitter-keys.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ng8MUlzhG8av"
   },
   "outputs": [],
   "source": [
    "# twitter auth to use\n",
    "\n",
    "# setting variables: tokens: # NOTE: THESE ARE SENSITIVE INFORMATION AND THEREFORE NOT SHARED HERE.\n",
    "\n",
    "# copy the keys-template.json file from the code directory to your home directory (or modify the path below), \n",
    "# and enter the respective keys and tokens. \n",
    "\n",
    "with open(os.path.join(os.path.expanduser(\"~\"),\n",
    "                       'twitter-keys.json'),\n",
    "         'r') as ifile:\n",
    "    keys = json.load(ifile)\n",
    "\n",
    "auth = tweepy.OAuthHandler(keys['consumer_key'], keys['consumer_secret'])\n",
    "auth.set_access_token(keys['access_token'], keys['access_token_secret'])\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# verify, this works with one's own timelines last 5 tweets (and casually check twitter while at work)\n",
    "public_tweets = api.home_timeline()\n",
    "for n, tweet in enumerate(public_tweets):\n",
    "    print(tweet.text)\n",
    "    if n == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RwMWqn-Vvy3c"
   },
   "outputs": [],
   "source": [
    "def limit_handled(cursor):\n",
    "    while True:\n",
    "        try:\n",
    "            yield cursor.next()\n",
    "        except tweepy.TweepError as msg: #tweepy.TweepError as msg:\n",
    "            print(f'Pausing for 1 min due to {msg}.')\n",
    "            time.sleep(60)\n",
    "        except StopIteration:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "6IhvcfIzlQ-T",
    "outputId": "33d51036-958d-44df-dc55-0328dab10e7f"
   },
   "outputs": [],
   "source": [
    "cc_hashtags = \"#globalwarming #climatebrawl #climategate #climatechange #savetheplanet #environment #nature #climate #climatecrisis #ecofriendly #earth #sustainability #climatechangeisreal #climateemergency #climateaction #climatestrike #gogreen #zerowaste #gretathunberg #fridaysforfuture #green #savetheearth #plasticfree #pollution #sustainable #climatejustice #recycle #saveourplanet #globalwarmingisreal #eco #bhfyp\"\n",
    "cc_hashtags = cc_hashtags.split(\"#\")\n",
    "cc_hashtags.extend(['climatedenial', 'nca4', 'gobalchange', 'bigoil', 'ecofraud', 'climatechangehoax', 'climateaction', 'climatechange', 'climatecrisis', 'globalwarming', 'climateaction', 'climate', 'climateemergency', 'climatehysteria', 'climatehoax', 'climatealarmism', 'climatechangealarmism', 'climatechangehoax', 'climatechangehysteria', 'globalwarminghysteria', 'climatechangefraud', 'climateemergencyhoax', 'climatechangescam', 'globalwarminghoax', 'globalwarmingalarmism', 'globalwarmingcult', 'climatechangefrenzy', 'globalwarmingfraud', 'globalwarmingscam', 'globalwarmingnonsense', 'globalwarmingbullshit', 'climatefraud', 'climatescam', 'climatecult', 'climatenonsense', 'climatebullshit', 'climatechangebullshit', 'climatechangenonsense', 'climatechangecult'])\n",
    "cc_hashtags = [x.strip() for x in cc_hashtags if x]\n",
    "\n",
    "cc_hashtags = set(cc_hashtags)\n",
    "\n",
    "cc_keywords = {'climate change', 'global warning', 'carbon dioxide', 'greenhouse gas', 'emissions', 'weather vs climate', 'fossil fuels', 'sea-level rise', 'global average temperature', 'renewable energy', 'unfccc', 'indc', 'ipcc', 'greenhouse effect', 'the denial machine', 'clexit coalition'}\n",
    "print(cc_hashtags)\n",
    "print(cc_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gjcaGeibmuh"
   },
   "outputs": [],
   "source": [
    "def cc_tweet_percentage(user_handle, hashtag_set=cc_hashtags, word_set=cc_keywords, max_number_of_tweets=200):\n",
    "    # print(f'calculating the cc_percentage for {user_handle}')\n",
    "    # hashtags = []\n",
    "    mentions = []\n",
    "    tweets_text = []\n",
    "    tweet_count = 0\n",
    "    cc_tweets = 0\n",
    "\n",
    "    for status in limit_handled(tweepy.Cursor(api.user_timeline, screen_name=user_handle).items()):\n",
    "      tweet_count += 1\n",
    "      if max_number_of_tweets and tweet_count > max_number_of_tweets:\n",
    "        break\n",
    "      text = status.text\n",
    "      \n",
    "      hashtags = {tag['text'].lower() for tag in status._json['entities']['hashtags']}\n",
    "\n",
    "      if not hashtag_set.isdisjoint(hashtags): # there is an overlap between the hashtags in the tweet and our hashtag list\n",
    "        cc_tweets += 1\n",
    "        continue # we don't have to look at the text now\n",
    "      \n",
    "      for pharse in word_set:\n",
    "        if pharse in text.lower():\n",
    "          cc_tweets += 1\n",
    "          break\n",
    "     #  print(text)\n",
    "    print(f'{user_handle}Â -> cc_tweets: {cc_tweets}, tweet_count: {tweet_count}')\n",
    "    return cc_tweets, tweet_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XPFVHF2ZqdH0"
   },
   "outputs": [],
   "source": [
    "\n",
    "def influencer_cc_score(influencer_handle, max_followers=200, min_statuses=10, country_codes={'US'}):\n",
    "  print(f'calculating the influencer_cc_score for {influencer_handle}.')\n",
    "  cc_tweet_percentages = []\n",
    "  followers = limit_handled(tweepy.Cursor(api.followers, screen_name=influencer_handle, count=max_followers).items())\n",
    "  for n, follower in enumerate(followers):\n",
    "    follower_handle = follower.screen_name\n",
    "    # print(f'looking at {follower_handle}')\n",
    "    # filter for the followers here: exclude people with less than \n",
    "    if follower._json['statuses_count'] < min_statuses:\n",
    "      #print('not enough tweets')\n",
    "      continue\n",
    "    if follower.protected:\n",
    "      continue\n",
    "    # if not follower._json['derived']['country_code'] in country_codes:\n",
    "    #  continue\n",
    "\n",
    "    # print(f'{influencer_handle} s follower: {follower}')\n",
    "    # try:\n",
    "    cc, total = cc_tweet_percentage(follower_handle)\n",
    "    # print(f'{cc} / {total} climate change tweets')\n",
    "    perc = cc / total\n",
    "    cc_tweet_percentages.append(perc)\n",
    "    # except tweepy.TweepError:\n",
    "    #   time.sleep(60) \n",
    "    if n == max_followers:\n",
    "      break\n",
    "  print(f'Got cc percentages: {cc_tweet_percentages}')\n",
    "  return cc_tweet_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_d5KRJAwf5l"
   },
   "outputs": [],
   "source": [
    "def get_follower_count(handle):\n",
    "  user = api.get_user(handle)\n",
    "  return user._json['followers_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5x4VzBVxePG"
   },
   "outputs": [],
   "source": [
    "def percentage_above_threshold(values, threshold):\n",
    "  if len(values) == 0:\n",
    "    return np.nan\n",
    "  above = sum(np.asarray(values) > threshold) # summing boolean variables\n",
    "  return above / len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pyVoqAjvJ0P"
   },
   "outputs": [],
   "source": [
    "# reworked:\n",
    "\n",
    "def calculate_influencer_df(influencer_list, influencer_dict):\n",
    "  # init stuff\n",
    "\n",
    "  for influencer in influencer_list:\n",
    "    influencer_dict[influencer] = {}\n",
    "    cc_tweets, tweet_count = cc_tweet_percentage(influencer)\n",
    "    follower_count = get_follower_count(influencer)\n",
    "\n",
    "    influencer_dict[influencer]['FollowerCount'] = follower_count\n",
    "\n",
    "    print(f'Influencer: {influencer} -> {cc_tweets} / {tweet_count} tweets mentioning climate change')\n",
    "\n",
    "    influencer_dict[influencer]['cc_tweet_percentage'] = cc_tweets / tweet_count\n",
    "    influencer_dict[influencer]['cc_tweetcc_tweet_absolute_percentage'] = cc_tweets\n",
    "    influencer_dict[influencer]['total_tweets'] =  tweet_count\n",
    "    \n",
    "    follower_cc_percentages = influencer_cc_score(influencer)\n",
    "    # follower_cc_percentages = [0.1, 0.2, 0.1, 0.0, 0.0] # testing only\n",
    "\n",
    "    influencer_dict[influencer]['follower_cc_score_raw'] = follower_cc_percentages\n",
    "    influencer_dict[influencer]['follower_cc_score_n_entries'] = len(follower_cc_percentages)\n",
    "    influencer_dict[influencer]['follower_cc_score_mean'] = np.mean(follower_cc_percentages)\n",
    "    influencer_dict[influencer]['follower_cc_score_any'] = percentage_above_threshold(follower_cc_percentages, 0.0)\n",
    "\n",
    "\n",
    "    print(f'. Follower cc tweet percentages: {follower_cc_percentages}')\n",
    "\n",
    "  return influencer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "J0PfiheMrKjZ",
    "outputId": "7d599c28-d7b5-4b91-f671-d121c3fef49f"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "influencer_list = ['ClimateDepot', 'LeoDiCaprio', 'Beyonce', 'R_Thaler', 'williamusa22', 'GretaThunberg', 'realdonaldtrump', 'paulkrugman', 'billieeilish', 'bdemelle',\n",
    "                   'junkscience', 'lindaunobel']\n",
    "influencer_dict = {}\n",
    "\n",
    "filled_influencer_dict = calculate_influencer_df(influencer_list, influencer_dict) \n",
    "filled_influencer_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UpNtjtgEGSA8"
   },
   "outputs": [],
   "source": [
    "# Due to errors, the dict object could not be retrieved. Instead we parsed the logs with the following methods:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyojoePJ2fjC"
   },
   "outputs": [],
   "source": [
    "# parsing the logs\n",
    "\n",
    "columns = ['Name', 'FollowerCount', 'CCTweets', 'TotalTweets']\n",
    "\n",
    "def parse_logs(logs, influencers, columns):\n",
    "  out = {influencer: {} for influencer in influencers}\n",
    "  for line in logs.split('\\n'):\n",
    "    if '__main__' in line:\n",
    "      continue\n",
    "    if line.startswith('Pausing'):\n",
    "      continue\n",
    "    if line.startswith('/'): # warnings and errors\n",
    "      continue\n",
    "    if line.startswith('calculating'):\n",
    "      continue\n",
    "    if line.startswith('Got'):\n",
    "      continue\n",
    "    if 'Follower cc tweet' in line:\n",
    "      continue\n",
    "    if line.startswith('Influencer'): \n",
    "      splitted = line.split() # Influencer: williamusa22 -> 0 / 1 tweets mentioning climate change\n",
    "      influencer_name = splitted[1]\n",
    "      cc_tweets = splitted[3]\n",
    "      total_tweets = splitted[5]\n",
    "      out[influencer_name]['CCTweets'] = cc_tweets\n",
    "      out[influencer_name]['TotalTweets'] = total_tweets\n",
    "      out[influencer_name]['CCPercentage'] = int(cc_tweets) / int(total_tweets)\n",
    "\n",
    "      out[influencer_name]['FollowerCCPercentages'] = []\n",
    "      out[influencer_name]['FollowerCCPercentagesRaw'] = []\n",
    "    # majority of lines: last influencers followers:\n",
    "    splits = line.split()\n",
    "    if len(splits) == 0:\n",
    "      continue\n",
    "    if splits[0] in influencers: # log for calculating the next influencers metrics\n",
    "      continue\n",
    "\n",
    "    cc_tweets = int(splits[3].replace(',', ''))\n",
    "    total_tweets = int(splits[5].strip())\n",
    "\n",
    "    out[influencer_name]['FollowerCCPercentagesRaw'].append([cc_tweets, total_tweets])\n",
    "    out[influencer_name]['FollowerCCPercentages'].append(cc_tweets / total_tweets)\n",
    "  return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ren5eQZ72hKJ"
   },
   "outputs": [],
   "source": [
    "influencer_list = ['williamusa22', 'GretaThunberg', 'realdonaldtrump', 'paulkrugman']\n",
    "\n",
    "\n",
    "log = \"\"\"\n",
    "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: generator 'limit_handled' raised StopIteration\n",
    "  if __name__ == '__main__':\n",
    "williamusa22 -> cc_tweets: 0, tweet_count: 1\n",
    "Influencer: williamusa22 -> 0 / 1 tweets mentioning climate change\n",
    "calculating the influencer_cc_score for williamusa22.\n",
    "Pausing for 1 min due to [{'message': 'Rate limit exceeded', 'code': 88}].\n",
    "Pausing for 1 min due to [{'message': 'Rate limit exceeded', 'code': 88}].\n",
    "...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srCREXXM2o8T"
   },
   "outputs": [],
   "source": [
    "parsed = parse_logs(log, influencer_list, columns)\n",
    "\n",
    "print('Printing return')\n",
    "print(parsed)\n",
    "\n",
    "\n",
    "# process the parsed data\n",
    "for influencer in parsed:\n",
    "  try:\n",
    "    parsed[influencer]['FollowerNonZeroCCTweetsPercentage'] = sum(np.asarray(parsed[influencer]['FollowerCCPercentages']) > 0) / len(parsed[influencer]['FollowerCCPercentages'])\n",
    "    parsed[influencer]['FollowerCCTweetAverage'] = np.mean(parsed[influencer]['FollowerCCPercentages'])\n",
    "  except KeyError:\n",
    "    print(f'Problem for {influencer}')\n",
    "df = pd.DataFrame(parsed).T\n",
    "\n",
    "\n",
    "print(df.drop(columns=['FollowerCCPercentages', 'FollowerCCPercentagesRaw']).to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "un0bjI0524CA"
   },
   "outputs": [],
   "source": [
    "# the CSV files generated by this function were further analysed in a google spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sciathon - Communicating climate change - Leveraging the Twitter API",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
